{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0778df84",
   "metadata": {},
   "source": [
    "# Otimização de Hiperparâmetros (Random Forest)\n",
    "\n",
    "## Refinamento Final do Modelo Selecionado\n",
    "\n",
    "Neste notebook, o objetivo é refinar o Random Forest, que foi selecionado na Etapa 7 como o modelo vencedor (AUC: 0.9278, Recall: 0.60).\n",
    "\n",
    "A otimização de hiperparâmetros visa explorar combinações de configurações que podem:\n",
    "1.  **Aumentar o Recall** (nossa métrica de negócio prioritária) acima de $0.60$.\n",
    "2.  Melhorar o AUC e o F1-Score sem prejudicar a Precisão.\n",
    "\n",
    "Utilizaremos o **RandomizedSearchCV** por ser mais eficiente computacionalmente que o GridSearch, permitindo explorar um espaço de busca mais amplo rapidamente. O critério de avaliação (`scoring`) será definido como `'recall'` para garantir que a busca priorize o nosso objetivo de captação.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79949c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup inicial concluído\n"
     ]
    }
   ],
   "source": [
    "# Setup e Carregamento de Dados\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n",
    "from scipy.stats import randint\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "from features.custom_transformers import BinaryMapper, MonthMapper\n",
    "\n",
    "# Carregando os dados\n",
    "try:\n",
    "    df = pd.read_csv('../data/bank-full.csv', sep = ';')\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo não encontrado. Verifique o caminho.\")\n",
    "    raise\n",
    "\n",
    "# Pré-processamento básico\n",
    "# Renomeando a coluna alvo\n",
    "df.rename(columns={'y': 'target'}, inplace = True)\n",
    "# Mapeamento da coluna alvo\n",
    "df['target'] = df['target'].map({'yes': 1, 'no': 0})\n",
    "# Tratamento do 'unknown' na coluna 'contact' aplicando a Moda\n",
    "df['contact'] = df['contact'].replace('unknown', df['contact'].mode()[0])\n",
    "\n",
    "# Separação dos dados\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)\n",
    "\n",
    "# DEfinição do ColumnTransformer\n",
    "binary_cols = ['default', 'housing', 'loan']\n",
    "ordinal_cols = ['month']\n",
    "nominal_cols = ['job', 'marital', 'education', 'contact', 'poutcome']\n",
    "numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binary', BinaryMapper(), binary_cols),\n",
    "        ('month', MonthMapper(), ordinal_cols),\n",
    "\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), \n",
    "        [f for f in nominal_cols if f not in binary_cols]), # Uma abordagem diferente para evitar a duplicação de colunas\n",
    "\n",
    "        ('scaler', StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Aplicação do pré-processamento\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Setup inicial concluído\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1f52cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Melhores prâmetros encontrados: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 259}\n",
      "\n",
      "Melhor recall médio(Cross Validation): 0.8223\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search para RF\n",
    "\n",
    "# Configuração do modelo base\n",
    "rf_base = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# DEfinindo o espaço de busca, utilizando o randint\n",
    "params = {\n",
    "    'n_estimators': randint(low=100, high=1000),\n",
    "    'max_depth': randint(low=10, high=50),\n",
    "    'min_samples_split': randint(low=2, high=20),\n",
    "    'min_samples_leaf': randint(low=1, high=10),\n",
    "    'max_features': ['sqrt', 'log2', None]    \n",
    "}\n",
    "\n",
    "# Configuração do RandomizedSearch com o recall como métrica\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf_base,\n",
    "    param_distributions = params,\n",
    "    n_iter = 50,\n",
    "    scoring = 'recall',\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# Executando e exibindo os resultados\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Melhores prâmetros encontrados: {rf_random.best_params_}\")\n",
    "print(f\"\\nMelhor recall médio(Cross Validation): {rf_random.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e962e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Resultados da Otimização (Randomized Search)\n",
    "\n",
    "O **Random Forest** foi refinado para priorizar o **Recall** (captação da classe 'yes') e os resultados de validação cruzada (CV) superaram em muito o modelo *baseline* e o modelo RF padrão:\n",
    "\n",
    "| Modelo | Recall Médio (CV) | Principais Parâmetros |\n",
    "| :--- | :--- | :--- |\n",
    "| **Logística Otimizada (Baseline)** | $\\approx 0.50$ | - |\n",
    "| **Random Forest Otimizado** | **$\\mathbf{0.8223}$** | `max_depth: 10`, `n_estimators: 259` |\n",
    "\n",
    "* **`max_depth: 10`**: A profundidade encontrada é significativamente menor do que o padrão, sugerindo que o modelo ótimo é mais simples e menos propenso ao *overfitting* do que se pensava.\n",
    "* **`Recall: 0.8223`**: Este valor na validação cruzada indica que o modelo otimizado pode identificar **mais de 82%** dos clientes que subscreverão o depósito, representando um potencial de **ganho de mais de 30 pontos percentuais** sobre a nossa *baseline* inicial.\n",
    "\n",
    "---\n",
    "\n",
    "### Validação e Ajuste Fino de Limiar (Modelo Otimizado)\n",
    "\n",
    "A otimização de hiperparâmetros elevou dramaticamente o potencial preditivo do nosso modelo. A próxima validar o modelo no conjunto de teste, com os parâmetros encontrados, para obter o **Recall real** e **ajustar o limiar novamente**.\n",
    "\n",
    "### Objetivo desta Validação\n",
    "\n",
    "1.  Confirmar o poder preditivo do novo modelo no conjunto de teste (cálculo do **AUC-ROC**).\n",
    "2.  Analisar a Curva ROC e a Tabela de Thresholds para encontrar o **novo limiar de corte**, buscando o melhor *trade-off* entre **Recall (acima de $0.70$)** e **Precisão**.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8331571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score (Random Forest Otimizado): 0.9131\n",
      "Recall Máximo do Modelo Selecionado (CV): 0.8223\n",
      "\n",
      "--- Inspecionando Thresholds Chave (Recall > 0.65) ---\n",
      "     Threshold    Recall  Precision_Proxy\n",
      "628   0.623902  0.650284         0.916719\n",
      "629   0.623582  0.650284         0.916594\n",
      "630   0.623514  0.651229         0.916594\n",
      "631   0.622886  0.651229         0.916218\n",
      "632   0.622848  0.652174         0.916218\n",
      "633   0.621899  0.652174         0.915341\n",
      "634   0.621894  0.653119         0.915341\n",
      "635   0.621800  0.653119         0.915216\n",
      "636   0.621506  0.654064         0.915216\n",
      "637   0.621463  0.654064         0.915091\n"
     ]
    }
   ],
   "source": [
    "# Validadação final do modelo RF\n",
    "\n",
    "rf_optimized_model = rf_random.best_estimator_\n",
    "\n",
    "y_proba_rf_optimized = rf_optimized_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr_opt, tpr_opt, thresholds_opt = roc_curve(y_test, y_proba_rf_optimized)\n",
    "roc_auc_opt = auc(fpr_opt, tpr_opt)\n",
    "\n",
    "threshold_df_opt = pd.DataFrame({\n",
    "    'Threshold': thresholds_opt,\n",
    "    'Recall': tpr_opt,\n",
    "    'Precision_Proxy': 1 - fpr_opt \n",
    "})\n",
    "\n",
    "print(f\"AUC-ROC Score (Random Forest Otimizado): {roc_auc_opt:.4f}\")\n",
    "print(f\"Recall Máximo do Modelo Selecionado (CV): {rf_random.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n--- Inspecionando Thresholds Chave (Recall > 0.65) ---\")\n",
    "print(threshold_df_opt[threshold_df_opt['Recall'] >= 0.65].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1341",
   "metadata": {},
   "source": [
    "### Análise Pós-Otimização do Limiar\n",
    "\n",
    "A execução do modelo Random Forest otimizado no conjunto de teste revelou um **AUC-ROC de $0.9131$**, confirmando seu excelente poder preditivo.\n",
    "\n",
    "O principal *insight* é a relação entre o *threshold* e o Recall:\n",
    "\n",
    "* **Modelo Anterior:** Alcançava um Recall de **$0.60$** com um *threshold* baixo de $\\mathbf{0.3333}$.\n",
    "* **Modelo Otimizado:** Conseguimos atingir um Recall de $\\mathbf{0.65}$ (nossa nova meta) com um *threshold* muito mais alto, de $\\mathbf{0.6239}$.\n",
    "\n",
    "#### Conclusão de Negócio\n",
    "O modelo é agora significativamente mais **confiante** em suas previsões. Ao usar o limiar de **$0.6239$**, mantemos a alta captação de clientes ('yes') e, implicitamente, a alta Precisão para a classe 'no' (evitando Falsos Positivos) devido à alta confiança das probabilidades geradas. A nova validação final usará este limiar para confirmar a performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados Finais do Modelo Selecionado\n",
    "\n",
    "Nesta etapa, confirmamos o desempenho do **Random Forest Otimizado** aplicando o **limiar de decisão final (0.6239)**, que foi ajustado para maximizar a captação de clientes ('yes') no patamar de **65% de Recall**.\n",
    "\n",
    "O modelo otimizado será comparado com o modelo *baseline* (Regressão Logística Otimizada) e o modelo Random Forest anterior para determinar o ganho real de negócio.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "863107ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusão Final:\n",
      "[[7320  665]\n",
      " [ 370  688]]\n",
      "\n",
      "Relatório de Classificação Final:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      7985\n",
      "           1       0.51      0.65      0.57      1058\n",
      "\n",
      "    accuracy                           0.89      9043\n",
      "   macro avg       0.73      0.78      0.75      9043\n",
      "weighted avg       0.90      0.89      0.89      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicação do limiar otimizado e relatório final\n",
    "\n",
    "optimal_threshrold_rf_final = 0.623902\n",
    "\n",
    "y_pred_rf_final = (y_proba_rf_optimized >= optimal_threshrold_rf_final).astype(int)\n",
    "\n",
    "print(\"\\nMatriz de Confusão Final:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf_final))\n",
    "\n",
    "print(\"\\nRelatório de Classificação Final:\")\n",
    "print(classification_report(y_test, y_pred_rf_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497d5ba",
   "metadata": {},
   "source": [
    "### Conclusão Final do Projeto e Decisão de Negócio\n",
    "\n",
    "O objetivo principal deste projeto era desenvolver um modelo preditivo capaz de maximizar o **Recall** (taxa de captação de clientes que subscreverão o depósito), visando atingir uma meta mínima de 60%.\n",
    "\n",
    "| Modelo e Limiar | Recall | Precision | AUC-ROC |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Logística Otimizada (Baseline)** | 0.50 | 0.57 | 0.8912 |\n",
    "| **Random Forest Padrão (Limiar 0.33)** | 0.60 | 0.57 | 0.9278 |\n",
    "| **Random Forest Otimizado (Limiar 0.6239)** | **0.65** | 0.51 | 0.9131 |\n",
    "\n",
    "### Decisão de Implementação (Deploy)\n",
    "\n",
    "O modelo a ser enviado para produção é o **Random Forest Otimizado com Limiar de $0.6239$**.\n",
    "\n",
    "#### Justificativa de Negócio:\n",
    "\n",
    "1.  **Meta Superada:** O modelo atingiu um Recall de **$0.65$**, superando a meta mínima de 60%. Isso representa um **aumento de 15 pontos percentuais** na captação de clientes em comparação com a *baseline* de Regressão Logística Otimizada.\n",
    "2.  **Trade-off Aceitável:** O aumento do Recall de $0.60$ para $0.65$ resultou em uma ligeira queda na Precisão (de $0.57$ para $0.51$). Esta troca significa que, para cada 100 contatos que o modelo prevê como 'yes', 51 de fato subscreverão. Este *trade-off* é considerado positivo para o negócio, pois o valor financeiro de um depósito capturado supera o custo de contatar mais Falsos Positivos.\n",
    "\n",
    "O projeto está completo, com um modelo robusto, otimizado e pronto para ser integrado ao sistema de campanha de marketing.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
